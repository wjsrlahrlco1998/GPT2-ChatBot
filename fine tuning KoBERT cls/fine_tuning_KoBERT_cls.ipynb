{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21d2f73",
   "metadata": {},
   "source": [
    "## 1. 사전 패키지 설치"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b05a011",
   "metadata": {},
   "source": [
    "!pip install mxnet\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers==3.0.2\n",
    "!pip install torch\n",
    "\n",
    "#깃허브에서 KoBERT 파일 로드\n",
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c0dc5",
   "metadata": {},
   "source": [
    "## 2. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f316e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6df680",
   "metadata": {},
   "source": [
    "## 3. GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e63f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cde5fa",
   "metadata": {},
   "source": [
    "## 4. train data 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd7ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 진짜! 사무실에서 피지 말라니깐! 간접흡연이 얼마나 안좋은데!</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그럼 직접흡연하는 난 얼마나 안좋겠니? 안그래? 보면 꼭... 지 생각만 하고.</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손님 왔어요.</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>손님? 누구?</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>몰라요. 팀장님 친구래요.</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Question emotion\n",
       "0          아 진짜! 사무실에서 피지 말라니깐! 간접흡연이 얼마나 안좋은데!      분노\n",
       "1  그럼 직접흡연하는 난 얼마나 안좋겠니? 안그래? 보면 꼭... 지 생각만 하고.      혐오\n",
       "2                                       손님 왔어요.      중립\n",
       "3                                       손님? 누구?      중립\n",
       "4                                몰라요. 팀장님 친구래요.      중립"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_data = pd.read_csv('../data/GPT3_ChatBot_data.csv')\n",
    "emo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae367e8f",
   "metadata": {},
   "source": [
    "## 5. 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에서 ['중립', '공포', '놀람']은 제외\n",
    "emo_data = emo_data[~emo_data['emotion'].str.contains(\"중립\", na=False, case=False)]\n",
    "emo_data = emo_data[~emo_data['emotion'].str.contains(\"공포\", na=False, case=False)]\n",
    "emo_data = emo_data[~emo_data['emotion'].str.contains(\"놀람\", na=False, case=False)]\n",
    "\n",
    "# 숫자 라벨링\n",
    "emo_data.loc[(emo_data['emotion'] == \"혐오\"), 'emotion'] = 0  #혐오 => 0\n",
    "emo_data.loc[(emo_data['emotion'] == \"행복\"), 'emotion'] = 1  #행복 => 1\n",
    "emo_data.loc[(emo_data['emotion'] == \"분노\"), 'emotion'] = 0  #분노 => 0\n",
    "emo_data.loc[(emo_data['emotion'] == \"슬픔\"), 'emotion'] = 2  #슬픔 => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82993c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6856"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "for q, label in zip(emo_data['Question'], emo_data['emotion'])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)\n",
    "\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793934d",
   "metadata": {},
   "source": [
    "## 6. 데이터 분할 7.5 : 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559fe69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239d2f7",
   "metadata": {},
   "source": [
    "## 7. KoBERT의 학습 데이터에 맞게 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573baa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 전처리 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0659620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70373412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/lab06/세미프로젝트/GPT3 챗봇/ChatBot_GPT3 & 2/.cache/kobert_v1.zip\n",
      "using cached model. /home/lab06/세미프로젝트/GPT3 챗봇/ChatBot_GPT3 & 2/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/lab06/세미프로젝트/GPT3 챗봇/ChatBot_GPT3 & 2/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ece17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# torch 형식의 dataset을 만들기\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96f7da",
   "metadata": {},
   "source": [
    "## 8. KoBERT 분류기 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ecab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT 모델 클래스(분류기)\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d0f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c6cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#optimizer Params와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 옵티마이저와 손실함수 생성\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f84c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f747a",
   "metadata": {},
   "source": [
    "## 9. KoBERT 분류기 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf46515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18854/2673822008.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bda5e6ed6a24da9a42ec1442dd417cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.2462388277053833 train acc 0.21875\n",
      "epoch 1 train acc 0.5983796296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18854/2673822008.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f09d185f92441fc8f1de4b2c6e19e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.7205324074074073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6c1f15e04147ee837b6f63969eafad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.8380646705627441 train acc 0.671875\n",
      "epoch 2 train acc 0.75643588664422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ded601015e4606b7360b1f5aa8c8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.7801388888888888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2abd946333492a875fd1b0942a3c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.6314377188682556 train acc 0.796875\n",
      "epoch 3 train acc 0.844942480359147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b0b180a0c04196a71c42af486d0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8031944444444444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7f869cf46f4f7f9b56c2409e4ea807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.42739397287368774 train acc 0.828125\n",
      "epoch 4 train acc 0.9018132716049383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05be1a47824f4ec0ac39d74b15cac081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.7770833333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276dd76751314b4182ee90a5f119e7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.3328074514865875 train acc 0.890625\n",
      "epoch 5 train acc 0.9400077160493827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05436907ee984b85ab023625a6a3bb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.7912962962962963\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5ef2f",
   "metadata": {},
   "source": [
    "## 10. 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6981b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/lab06/세미프로젝트/GPT3 챗봇/ChatBot_GPT3 & 2/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "    \n",
    "    result_emo = None\n",
    "    \n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"분노가\")\n",
    "                result_emo = '분노'\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"행복이\")\n",
    "                result_emo = '행복'\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "                result_emo = '슬픔'\n",
    "                \n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73124065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n"
     ]
    }
   ],
   "source": [
    "predict(\"너무 짜증나는 하루구만...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8133906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n"
     ]
    }
   ],
   "source": [
    "predict(\"힘이없다...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab23232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 행복이 느껴집니다.\n"
     ]
    }
   ],
   "source": [
    "predict('완벽한 하루였어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea484e4",
   "metadata": {},
   "source": [
    "## 11. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e87047",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 저장 코드\n",
    "torch.save(model, './model/KoBERT_cls_model.pt')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9d8b008",
   "metadata": {},
   "source": [
    "모델 불러오기 코드\n",
    "\n",
    "[사전 필요 코드]\n",
    "1. BERTDataset 클래스 정의\n",
    "\n",
    "2. BERTClassifier 클래스 정의\n",
    "\n",
    "3. vocab 불러오기\n",
    "_, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "4. 튜닝된 모델 불러오기\n",
    "model_kobert = torch.load('../model/KoBERT_cls_model.pt')\n",
    "model_kobert.eval()\n",
    "\n",
    "5. GPU device 지정\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "6. params 설정\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "\n",
    "7.토크나이저 설정\n",
    "tokenizer_kobert = get_tokenizer()\n",
    "tok_kobert = nlp.data.BERTSPTokenizer(tokenizer_kobert, vocab, lower=False)\n",
    "\n",
    "8. predict 함수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
