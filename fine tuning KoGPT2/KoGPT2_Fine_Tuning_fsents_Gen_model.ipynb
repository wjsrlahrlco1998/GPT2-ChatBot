{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e47ceb",
   "metadata": {},
   "source": [
    "## 1. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a42513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 09:22:07.850625: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-22 09:22:10.789372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:10.792965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:10.795628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:10.798637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-22 09:22:10.799017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:10.801667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:10.804246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:14.233596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:14.235440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:14.237012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-22 09:22:14.238525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12688 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72a980",
   "metadata": {},
   "source": [
    "## 2. KoGPT2 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aff9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "KoGPT2_sent_tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1875c874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.9.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'lm_head.weight', 'transformer.h.10.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.1.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "KoGPT2_sent_model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b723381",
   "metadata": {},
   "source": [
    "## 3. 학습 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e583bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>감정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이렇게 하는 거야.” 하며 시범을 보이자 그녀의 웃음소리가 병실 가득 메아리쳤다.</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그러나 이렇게 해서라도 아까 본 피범벅 동영상을 머릿속에서 지울 수 있다면, 그녀의...</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  문장  감정\n",
       "0      이렇게 하는 거야.” 하며 시범을 보이자 그녀의 웃음소리가 병실 가득 메아리쳤다.  행복\n",
       "1  그러나 이렇게 해서라도 아까 본 피범벅 동영상을 머릿속에서 지울 수 있다면, 그녀의...  슬픔"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 학습 데이터 로드\n",
    "train_data = pd.read_csv(\"./train data/train_gpt2_sent.csv\")\n",
    "train_data.drop(\"Unnamed: 0\", axis=1, inplace = True)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c74942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>감정</th>\n",
       "      <th>문장</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>행복</td>\n",
       "      <td>진짜 인버뤄-브뤠이트 같아.”일단 웃었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>행복</td>\n",
       "      <td>고마워.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   감정                       문장\n",
       "0  행복  진짜 인버뤄-브뤠이트 같아.”일단 웃었다.\n",
       "1  행복                     고마워."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[train_data.문장.map(len) < 30].reset_index(drop=True)\n",
    "train_data = train_data[['감정', '문장']]\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8565f9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "슬픔    1103\n",
       "분노     409\n",
       "행복     286\n",
       "Name: 감정, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.감정.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8841bc",
   "metadata": {},
   "source": [
    "## 4. 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6107fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params setting\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6bf7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 토큰화 함수\n",
    "def get_emo_data():\n",
    "    for question, answer in zip(train_data.감정.to_list(), train_data.문장.to_list()):\n",
    "        bos_token = [KoGPT2_sent_tokenizer.bos_token_id]\n",
    "        eos_token = [KoGPT2_sent_tokenizer.eos_token_id]\n",
    "        sent = KoGPT2_sent_tokenizer.encode('<usr>' + question + '<sys>' + answer) \n",
    "        yield bos_token + sent + eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9e3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 필요로하는 DataSet 생성\n",
    "dataset = tf.data.Dataset.from_generator(get_emo_data, output_types=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5215d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력데이터의 크기가 가변 일때 같은 크기로 읽을 수 있게 변환\n",
    "dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(None,), padding_values=KoGPT2_sent_tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066597f",
   "metadata": {},
   "source": [
    "## 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82112698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# 1, 옵티마이저 정의\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "\n",
    "# 2. Step 정의\n",
    "steps = len(train_data) // batch_size + 1\n",
    "print(steps)\n",
    "# 3. 에포치 설정(학습횟수)\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ebdc72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30780/808126332.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm_notebook(dataset, total=steps):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfba541d6a9489ca5546c3c9532d1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 2.60400867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a341ece930944246bf5e57e73d689cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    2] cost = 1.72206843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa2dc779f5041beb0bf8cd8d0307300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    3] cost = 1.35414803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826b538b591a4be3976fa5e2ac1dc2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    4] cost = 1.03839958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217a2be3e1c741f8aa75780e066e7296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    5] cost = 0.856860101\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm_notebook(dataset, total=steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = KoGPT2_sent_model(batch, labels=batch)\n",
    "            loss = result[0]\n",
    "            batch_loss = tf.reduce_mean(loss)\n",
    "            \n",
    "        grads = tape.gradient(batch_loss, KoGPT2_sent_model.trainable_variables)\n",
    "        adam.apply_gradients(zip(grads, KoGPT2_sent_model.trainable_variables))\n",
    "        epoch_loss += batch_loss / steps\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97559931",
   "metadata": {},
   "source": [
    "## 6. 전체 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59451a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KoGPT2_sent_model.save_pretrained('./model/Gen_sent_GPT2_model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6470f8e8",
   "metadata": {},
   "source": [
    "@ 모델 불러오기\n",
    "\n",
    "model = torch.load('./model/Gen_sent_GPT2_model.pt')\n",
    "model.eval() # 배치 정규화를 평가 모드로 설정 -> 올바른 추론 결과를 얻기 위한 필수 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e02ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./model/Gen_sent_GPT2_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "load_model = TFGPT2LMHeadModel.from_pretrained('./model/Gen_sent_GPT2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fdfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_answer_by_chatbot(user_text):\n",
    "    sent = '<usr>' + user_text + '<sys>'\n",
    "    input_ids = [KoGPT2_sent_tokenizer.bos_token_id] + KoGPT2_sent_tokenizer.encode(sent)\n",
    "    input_ids = tf.convert_to_tensor([input_ids])\n",
    "    output = load_model.generate(input_ids, max_length=50, do_sample=True, top_k=20)\n",
    "    sentence = KoGPT2_sent_tokenizer.decode(output[0].numpy().tolist())\n",
    "    chatbot_response = sentence.split('<sys> ')[1].replace('</s>', '')\n",
    "    return chatbot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b771b40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아즈윈은 한동안 방긋 웃지도 않았다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_answer_by_chatbot('슬픔')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
